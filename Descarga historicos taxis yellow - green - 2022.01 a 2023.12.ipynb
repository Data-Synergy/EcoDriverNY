{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ee3608a-f09e-4e61-8400-f2f248a97b93",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Descarga a dataframes (web scraping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ced3185-ee4a-455b-897a-10d534ab1bdb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Página de fuente datos https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "154a3fee-5fbd-4fc1-8482-56599e7ef20b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Descarga de yellow_tripdata_2022-01 2023-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbe47a53-2992-49be-9d14-ca1b13bfec9d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_yellow_2022_01 creado correctamente.\nDataFrame df_yellow_2022_02 creado correctamente.\nDataFrame df_yellow_2022_03 creado correctamente.\nDataFrame df_yellow_2022_04 creado correctamente.\nDataFrame df_yellow_2022_05 creado correctamente.\nDataFrame df_yellow_2022_06 creado correctamente.\nDataFrame df_yellow_2022_07 creado correctamente.\nDataFrame df_yellow_2022_08 creado correctamente.\nDataFrame df_yellow_2022_09 creado correctamente.\nDataFrame df_yellow_2022_10 creado correctamente.\nDataFrame df_yellow_2022_11 creado correctamente.\nDataFrame df_yellow_2022_12 creado correctamente.\nDataFrame df_yellow_2023_01 creado correctamente.\nDataFrame df_yellow_2023_02 creado correctamente.\nDataFrame df_yellow_2023_03 creado correctamente.\nDataFrame df_yellow_2023_04 creado correctamente.\nDataFrame df_yellow_2023_05 creado correctamente.\nDataFrame df_yellow_2023_06 creado correctamente.\nDataFrame df_yellow_2023_07 creado correctamente.\nDataFrame df_yellow_2023_08 creado correctamente.\nDataFrame df_yellow_2023_09 creado correctamente.\nDataFrame df_yellow_2023_10 creado correctamente.\nDataFrame df_yellow_2023_11 creado correctamente.\nDataFrame df_yellow_2023_12 creado correctamente.\nNo se pudo cargar el archivo yellow_tripdata_2024-01.parquet: HTTP Error 403: Forbidden\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Definir la lista de DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Iterar sobre los meses desde enero de 2021\n",
    "año = 2022\n",
    "mes = 1\n",
    "while True:\n",
    "    # Construir el nombre del archivo Parquet\n",
    "    nombre_archivo = f\"yellow_tripdata_{año}-{mes:02}.parquet\"\n",
    "    \n",
    "    # Construir la ruta del archivo Parquet\n",
    "    ruta_archivo = f\"https://d37ci6vzurychx.cloudfront.net/trip-data/{nombre_archivo}\"\n",
    "    \n",
    "    # Intentar cargar el archivo Parquet en un DataFrame\n",
    "    try:\n",
    "        df = pd.read_parquet(ruta_archivo)\n",
    "        dfs.append(df)\n",
    "        nombre_df = f\"df_yellow_{año}_{mes:02}\"\n",
    "        globals()[nombre_df] = df  # Asignar el DataFrame a una variable con el nombre adecuado\n",
    "        print(f\"DataFrame {nombre_df} creado correctamente.\")\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo cargar el archivo {nombre_archivo}: {e}\")\n",
    "        break  # Detener el bucle si no se puede cargar el archivo\n",
    "    \n",
    "    # Pasar al siguiente mes\n",
    "    mes += 1\n",
    "    if mes > 12:\n",
    "        mes = 1\n",
    "        año += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b1d98e6-cd4f-43e7-8ad4-54bc932947d0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Creación de table \"yellow_taxi\" en database \"basededatos_taxis\" en BigQuery de Google Cloud Plataform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16607bc5-16e5-4e7f-97ce-931fb0c1d512",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 8004.40it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_yellow_2022_01 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 8886.24it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_yellow_2022_02 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 9686.61it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_yellow_2022_03 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 8867.45it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_yellow_2022_04 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 7639.90it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_yellow_2022_05 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 9939.11it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_yellow_2022_06 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 6967.28it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_yellow_2022_07 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 6442.86it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_yellow_2022_08 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 7281.78it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_yellow_2022_09 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 8422.30it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_yellow_2022_10 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 8830.11it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_yellow_2022_11 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 10131.17it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_yellow_2022_12 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 9157.87it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_yellow_2023_01 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 7503.23it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_yellow_2023_02 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 8719.97it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_yellow_2023_03 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 8848.74it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_yellow_2023_04 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 8738.13it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_yellow_2023_05 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 7928.74it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_yellow_2023_06 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 9039.45it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_yellow_2023_07 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 8128.50it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_yellow_2023_08 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 11155.06it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_yellow_2023_09 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 8144.28it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_yellow_2023_10 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 6096.37it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_yellow_2023_11 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 8577.31it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_yellow_2023_12 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from google.auth import load_credentials_from_file\n",
    "from pandas.io import gbq\n",
    "\n",
    "# Cargar las credenciales desde el archivo JSON\n",
    "credentials, project_id = load_credentials_from_file(\n",
    "    \"/Workspace/Users/eliasemanuelalmada5757@gmail.com/basestaxis/automatizacion-taxis-nyc-d47c13651bca.json\"\n",
    ")\n",
    "\n",
    "# Asignar el ID del proyecto a la variable project_id\n",
    "project_id = \"automatizacion-taxis-nyc\"\n",
    "\n",
    "# Crear un bucle para cargar cada DataFrame\n",
    "for año in range(2022, 2024):  # desde 2022 hasta 2023\n",
    "    for mes in range(1, 13):  # desde enero hasta diciembre\n",
    "        # Construir el nombre del DataFrame\n",
    "        nombre_df = f\"df_yellow_{año}_{mes:02}\"\n",
    "        \n",
    "        try:\n",
    "            # Obtener el DataFrame con el nombre correspondiente\n",
    "            df = globals()[nombre_df]\n",
    "            \n",
    "            # Llamar a to_gbq() con las credenciales cargadas y el ID del proyecto\n",
    "            df.to_gbq(destination_table=\"basededatos_taxis.yellow_taxi\",\n",
    "                      project_id=project_id,\n",
    "                      if_exists=\"append\",  # Reemplazar los datos existentes\n",
    "                      credentials=credentials)\n",
    "            print(f\"DataFrame {nombre_df} cargado a BigQuery correctamente.\")\n",
    "        except KeyError:\n",
    "            print(f\"No se encontró el DataFrame {nombre_df}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb9cf96f-04d1-4e10-96af-58a186a5b75f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Descarga de green_tripdata_2022-01 2023-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6664ed30-7efb-4010-ab71-5d32fc9c947d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_green_2022_01 creado correctamente.\nDataFrame df_green_2022_02 creado correctamente.\nDataFrame df_green_2022_03 creado correctamente.\nDataFrame df_green_2022_04 creado correctamente.\nDataFrame df_green_2022_05 creado correctamente.\nDataFrame df_green_2022_06 creado correctamente.\nDataFrame df_green_2022_07 creado correctamente.\nDataFrame df_green_2022_08 creado correctamente.\nDataFrame df_green_2022_09 creado correctamente.\nDataFrame df_green_2022_10 creado correctamente.\nDataFrame df_green_2022_11 creado correctamente.\nDataFrame df_green_2022_12 creado correctamente.\nDataFrame df_green_2023_01 creado correctamente.\nDataFrame df_green_2023_02 creado correctamente.\nDataFrame df_green_2023_03 creado correctamente.\nDataFrame df_green_2023_04 creado correctamente.\nDataFrame df_green_2023_05 creado correctamente.\nDataFrame df_green_2023_06 creado correctamente.\nDataFrame df_green_2023_07 creado correctamente.\nDataFrame df_green_2023_08 creado correctamente.\nDataFrame df_green_2023_09 creado correctamente.\nDataFrame df_green_2023_10 creado correctamente.\nDataFrame df_green_2023_11 creado correctamente.\nDataFrame df_green_2023_12 creado correctamente.\nNo se pudo cargar el archivo green_tripdata_2024-01.parquet: HTTP Error 403: Forbidden\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Definir la lista de DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Iterar sobre los meses desde enero de 2021\n",
    "año = 2022\n",
    "mes = 1\n",
    "while True:\n",
    "    # Construir el nombre del archivo Parquet\n",
    "    nombre_archivo = f\"green_tripdata_{año}-{mes:02}.parquet\"\n",
    "    \n",
    "    # Construir la ruta del archivo Parquet\n",
    "    ruta_archivo = f\"https://d37ci6vzurychx.cloudfront.net/trip-data/{nombre_archivo}\"\n",
    "    \n",
    "    # Intentar cargar el archivo Parquet en un DataFrame\n",
    "    try:\n",
    "        df = pd.read_parquet(ruta_archivo)\n",
    "        dfs.append(df)\n",
    "        nombre_df = f\"df_green_{año}_{mes:02}\"\n",
    "        globals()[nombre_df] = df  # Asignar el DataFrame a una variable con el nombre adecuado\n",
    "        print(f\"DataFrame {nombre_df} creado correctamente.\")\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo cargar el archivo {nombre_archivo}: {e}\")\n",
    "        break  # Detener el bucle si no se puede cargar el archivo\n",
    "    \n",
    "    # Pasar al siguiente mes\n",
    "    mes += 1\n",
    "    if mes > 12:\n",
    "        mes = 1\n",
    "        año += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94921488-ded2-486a-8000-b181868c0c04",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "##### Creación de table \"green_taxi\" en database \"basededatos_taxis\" en BigQuery de Google Cloud Plataform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10cf16c9-045e-4f89-aab6-5df7be52f03b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 8224.13it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_green_2022_01 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 10255.02it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_green_2022_02 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 8081.51it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_green_2022_03 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 6288.31it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_green_2022_04 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 8559.80it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_green_2022_05 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 8559.80it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_green_2022_06 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 10433.59it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_green_2022_07 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 1860.00it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_green_2022_08 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 8830.11it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_green_2022_09 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 8886.24it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_green_2022_10 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 9845.78it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_green_2022_11 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 6808.94it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_green_2022_12 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 9177.91it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_green_2023_01 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 10512.04it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_green_2023_02 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 9845.78it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_green_2023_03 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 7958.83it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_green_2023_04 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 9754.20it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_green_2023_05 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 11066.77it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_green_2023_06 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 1967.31it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_green_2023_07 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 8738.13it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_green_2023_08 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 11275.01it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_green_2023_09 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 10255.02it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_green_2023_10 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 1771.24it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_green_2023_11 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 8559.80it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_green_2023_12 cargado a BigQuery correctamente.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from google.auth import load_credentials_from_file\n",
    "from pandas.io import gbq\n",
    "\n",
    "# Cargar las credenciales desde el archivo JSON\n",
    "credentials, project_id = load_credentials_from_file(\n",
    "    \"/Workspace/Users/eliasemanuelalmada5757@gmail.com/basestaxis/automatizacion-taxis-nyc-d47c13651bca.json\"\n",
    ")\n",
    "\n",
    "# Asignar el ID del proyecto a la variable project_id\n",
    "project_id = \"automatizacion-taxis-nyc\"\n",
    "\n",
    "# Crear un bucle para cargar cada DataFrame\n",
    "for año in range(2022, 2024):  # desde 2022 hasta 2023\n",
    "    for mes in range(1, 13):  # desde enero hasta diciembre\n",
    "        # Construir el nombre del DataFrame\n",
    "        nombre_df = f\"df_green_{año}_{mes:02}\"\n",
    "        \n",
    "        try:\n",
    "            # Obtener el DataFrame con el nombre correspondiente\n",
    "            df = globals()[nombre_df]\n",
    "            \n",
    "            # Llamar a to_gbq() con las credenciales cargadas y el ID del proyecto\n",
    "            df.to_gbq(destination_table=\"basededatos_taxis.green_taxi\",\n",
    "                      project_id=project_id,\n",
    "                      if_exists=\"append\",  # Reemplazar los datos existentes\n",
    "                      credentials=credentials)\n",
    "            print(f\"DataFrame {nombre_df} cargado a BigQuery correctamente.\")\n",
    "        except KeyError:\n",
    "            print(f\"No se encontró el DataFrame {nombre_df}.\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Descarga historicos taxis yellow - green - 2022.01 a 2023.12",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

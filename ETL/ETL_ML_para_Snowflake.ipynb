{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":66780,"status":"ok","timestamp":1713441417403,"user":{"displayName":"Allan Alvarez","userId":"10003369821085423122"},"user_tz":180},"id":"dpn_CdYGNFr5","outputId":"c49cc341-5080-4e19-a5a8-b8bbc2999f70"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyspark\n","  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=fe4160f0c7f7c89ea98c11e7b61d9f59a411a9597aefd496d2e1ab4732cf597a\n","  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","Successfully installed pyspark-3.5.1\n"]}],"source":["!pip install pyspark\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eJx7JTtgrZYu","executionInfo":{"status":"ok","timestamp":1713441471935,"user_tz":180,"elapsed":54545,"user":{"displayName":"Allan Alvarez","userId":"10003369821085423122"}},"outputId":"7ad3d3d0-5dbf-4f2a-9bc6-0316552f6304"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"uLJKxCC_7HBg"},"source":["###***Importacion de librerias***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VTvI340t7DK_"},"outputs":[],"source":["import pandas as pd\n","import pyarrow\n","import requests\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import LinearSegmentedColormap\n","import seaborn as sns\n","import numpy as np\n","import pyspark\n","from pyspark.sql import SparkSession\n","from pyspark.sql import functions as F\n","from pyspark.sql.functions import col\n","from pyspark.sql.functions import when\n","from pyspark.sql.window import Window\n","from pyspark.sql.functions import min, max\n","from pyspark.sql.functions import hour\n","from pyspark.sql.functions import to_timestamp, round\n","from pyspark.sql import SparkSession\n","from functools import reduce\n"]},{"cell_type":"markdown","source":["**Lee y carga el Archivo**"],"metadata":{"id":"G4qx7ZOo5Xw7"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":62017,"status":"ok","timestamp":1713441537326,"user":{"displayName":"Allan Alvarez","userId":"10003369821085423122"},"user_tz":180},"id":"Ql2Zym9bUW9r","outputId":"f12174db-27e1-4029-d15a-d46e03ff848b"},"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- VendorID: long (nullable = true)\n"," |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n"," |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n"," |-- passenger_count: double (nullable = true)\n"," |-- trip_distance: double (nullable = true)\n"," |-- RatecodeID: double (nullable = true)\n"," |-- store_and_fwd_flag: string (nullable = true)\n"," |-- PULocationID: long (nullable = true)\n"," |-- DOLocationID: long (nullable = true)\n"," |-- payment_type: long (nullable = true)\n"," |-- fare_amount: double (nullable = true)\n"," |-- extra: double (nullable = true)\n"," |-- mta_tax: double (nullable = true)\n"," |-- tip_amount: double (nullable = true)\n"," |-- tolls_amount: double (nullable = true)\n"," |-- improvement_surcharge: double (nullable = true)\n"," |-- total_amount: double (nullable = true)\n"," |-- congestion_surcharge: double (nullable = true)\n"," |-- airport_fee: double (nullable = true)\n","\n","+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n","|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n","+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n","|       1| 2022-01-01 00:35:40|  2022-01-01 00:53:29|            2.0|          3.8|       1.0|                 N|         142|         236|           1|       14.5|  3.0|    0.5|      3.65|         0.0|                  0.3|       21.95|                 2.5|        0.0|\n","|       1| 2022-01-01 00:33:43|  2022-01-01 00:42:07|            1.0|          2.1|       1.0|                 N|         236|          42|           1|        8.0|  0.5|    0.5|       4.0|         0.0|                  0.3|        13.3|                 0.0|        0.0|\n","|       2| 2022-01-01 00:53:21|  2022-01-01 01:02:19|            1.0|         0.97|       1.0|                 N|         166|         166|           1|        7.5|  0.5|    0.5|      1.76|         0.0|                  0.3|       10.56|                 0.0|        0.0|\n","|       2| 2022-01-01 00:25:21|  2022-01-01 00:35:23|            1.0|         1.09|       1.0|                 N|         114|          68|           2|        8.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        11.8|                 2.5|        0.0|\n","|       2| 2022-01-01 00:36:48|  2022-01-01 01:14:20|            1.0|          4.3|       1.0|                 N|          68|         163|           1|       23.5|  0.5|    0.5|       3.0|         0.0|                  0.3|        30.3|                 2.5|        0.0|\n","|       1| 2022-01-01 00:40:15|  2022-01-01 01:09:48|            1.0|         10.3|       1.0|                 N|         138|         161|           1|       33.0|  3.0|    0.5|      13.0|        6.55|                  0.3|       56.35|                 2.5|        0.0|\n","|       2| 2022-01-01 00:20:50|  2022-01-01 00:34:58|            1.0|         5.07|       1.0|                 N|         233|          87|           1|       17.0|  0.5|    0.5|       5.2|         0.0|                  0.3|        26.0|                 2.5|        0.0|\n","|       2| 2022-01-01 00:13:04|  2022-01-01 00:22:45|            1.0|         2.02|       1.0|                 N|         238|         152|           2|        9.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        12.8|                 2.5|        0.0|\n","|       2| 2022-01-01 00:30:02|  2022-01-01 00:44:49|            1.0|         2.71|       1.0|                 N|         166|         236|           1|       12.0|  0.5|    0.5|      2.25|         0.0|                  0.3|       18.05|                 2.5|        0.0|\n","|       2| 2022-01-01 00:48:52|  2022-01-01 00:53:28|            1.0|         0.78|       1.0|                 N|         236|         141|           2|        5.0|  0.5|    0.5|       0.0|         0.0|                  0.3|         8.8|                 2.5|        0.0|\n","|       2| 2022-01-01 00:55:03|  2022-01-01 01:04:25|            1.0|         1.91|       1.0|                 N|         141|         229|           2|        8.5|  0.5|    0.5|       0.0|         0.0|                  0.3|        12.3|                 2.5|        0.0|\n","|       2| 2022-01-01 00:31:06|  2022-01-01 00:34:14|            3.0|         0.82|       1.0|                 N|         114|          90|           2|        4.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         8.3|                 2.5|        0.0|\n","|       2| 2022-01-01 00:41:07|  2022-01-01 00:44:46|            3.0|         0.73|       1.0|                 N|         234|         113|           2|        4.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         8.3|                 2.5|        0.0|\n","|       2| 2022-01-01 00:56:34|  2022-01-01 01:12:04|            2.0|         2.16|       1.0|                 N|         246|          79|           1|       11.5|  0.5|    0.5|      3.06|         0.0|                  0.3|       18.36|                 2.5|        0.0|\n","|       2| 2022-01-01 00:39:46|  2022-01-01 00:47:36|            4.0|         1.43|       1.0|                 N|          43|         140|           1|        7.5|  0.5|    0.5|      2.26|         0.0|                  0.3|       13.56|                 2.5|        0.0|\n","|       2| 2022-01-01 00:58:06|  2022-01-01 01:05:45|            1.0|         1.58|       1.0|                 N|         239|         151|           2|        8.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        11.8|                 2.5|        0.0|\n","|       1| 2022-01-01 00:33:52|  2022-01-01 00:47:28|            3.0|          4.2|       1.0|                 N|         148|         141|           1|       14.0|  2.5|    0.5|      3.45|         0.0|                  0.3|       20.75|                 2.5|        0.0|\n","|       1| 2022-01-01 00:53:54|  2022-01-01 01:05:20|            2.0|          2.2|       1.0|                 N|         237|         107|           1|        9.5|  2.5|    0.5|      2.55|         0.0|                  0.3|       15.35|                 2.5|        0.0|\n","|       1| 2022-01-01 00:00:44|  2022-01-01 00:05:29|            1.0|          0.2|       1.0|                 N|           7|           7|           2|        5.0|  0.5|    0.5|       0.0|         0.0|                  0.3|         6.3|                 0.0|        0.0|\n","|       1| 2022-01-01 00:35:50|  2022-01-01 00:48:33|            2.0|          3.9|       1.0|                 N|         107|         263|           1|       13.0|  3.0|    0.5|      3.35|         0.0|                  0.3|       20.15|                 2.5|        0.0|\n","+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n","only showing top 20 rows\n","\n"]}],"source":["# Crea una sesión de Spark\n","spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n","\n","# Ruta de la carpeta que contiene los archivos Parquet\n","ruta = \"/content/drive/MyDrive/Proyecto FInal Henry/datos_tripdata/\"\n","\n","# Lista para almacenar los DataFrames de cada archivo\n","dfs = []\n","\n","# Itera sobre los años 2022 y 2023 y sobre todos los meses\n","for year in range(2022, 2024):\n","    for month in range(1, 13):\n","        filename = f\"yellow_tripdata_{year}-{month:02d}.parquet\"\n","        try:\n","            df = spark.read.parquet(ruta + filename)\n","            dfs.append(df)\n","        except:\n","            print(f\"No se encontró el archivo {filename}\")\n","\n","\n","df_total = reduce(lambda df1, df2: df1.union(df2), dfs)\n","df_total.printSchema()\n","df_total.show()\n"]},{"cell_type":"markdown","source":["**>>> ETL MODELOS ML EMISIONES**"],"metadata":{"id":"KiOHnNhsPZEa"}},{"cell_type":"markdown","source":["**Elimina columnas innecesarias**"],"metadata":{"id":"1qSY-gchPh1v"}},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col\n","\n","# Crear una sesión de Spark\n","spark = SparkSession.builder \\\n","    .appName(\"Eliminar columnas\") \\\n","    .getOrCreate()\n","\n","# Suponiendo que tu DataFrame se llama df_total\n","\n","# Eliminar las columnas especificadas\n","columnas_a_eliminar = [\"VendorID\", \"congestion_surcharge\" , \"improvement_surcharge\" , \"passenger_count\", \"payment_type\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"RatecodeID\", \"store_and_fwd_flag\",\n","                       \"PULocationID\", \"DOLocationID\", \"fare_amount\", \"extra\", \"mta_tax\", \"tip_amount\",\n","                       \"tolls_amount\", \"total_amount\", \"airport_fee\"]\n","\n","df_total_emis = df_total.drop(*columnas_a_eliminar)\n"],"metadata":{"id":"XgEPUvEPPYuV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Eliminación de nulos**"],"metadata":{"id":"DwQPWV8MPuqJ"}},{"cell_type":"code","source":["# Eliminar registros con valores nulos en todas las columnas\n","df_total_sin_nulos = df_total_emis.dropna(how=\"all\")\n","\n"],"metadata":{"id":"0B8UqR77PYrs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Agrega columnas con cálculos necesarios de consumo y costo de combustible y emisiones**"],"metadata":{"id":"oN9guWOQP_WQ"}},{"cell_type":"code","source":["from pyspark.sql.functions import col\n","\n","#Costo de combustible por milla = Precio del combustible por galón / Millas por galón\n","\n","#Donde:\n","#- *Precio del combustible por galón* es el precio del combustible por galón en dólares.\n","#- *Millas por galón* es la cantidad de millas que el vehículo puede recorrer con un galón de combustible.\n","\n","#Por ejemplo, si el precio del combustible por galón es de $3.00 y el vehículo tiene un consumo de combustible promedio de 25 millas por galón, el costo de combustible por milla sería:\n","\n","\n","\n","\n","# Calcular el costo de combustible (suponiendo un costo de $0.12 por milla)\n","df_total_sin_nulos = df_total_sin_nulos.withColumn(\"fuel_cost\", col(\"trip_distance\") * 0.12)\n","\n","# Calcular la eficiencia de combustible por milla\n","df_total_sin_nulos = df_total_sin_nulos.withColumn(\"fuel_efficiency_per_mile\", col(\"trip_distance\") / col(\"fuel_cost\"))\n","\n","# Calcular el consumo de combustible por viaje\n","df_total_sin_nulos = df_total_sin_nulos.withColumn(\"fuel_consumption_per_trip\", col(\"fuel_efficiency_per_mile\") * col(\"trip_distance\"))\n","\n","# Calcular el CO2 por milla (suponiendo una tasa de emisión de 0.5 toneladas de CO2 por milla)\n","df_total_sin_nulos = df_total_sin_nulos.withColumn(\"co2_per_mile\", col(\"trip_distance\") * 0.5)\n"],"metadata":{"id":"1ZeoQchUPYmm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Redondea los cálculos a 2 decimales**"],"metadata":{"id":"XrCJX3UbQT_8"}},{"cell_type":"code","source":["from pyspark.sql.functions import col, round\n","\n","# Redondear los valores de las columnas especificadas\n","df_total_redondeado = df_total_sin_nulos \\\n","    .withColumn(\"trip_distance\", round(col(\"trip_distance\"), 2)) \\\n","    .withColumn(\"fuel_efficiency_per_mile\", round(col(\"fuel_efficiency_per_mile\"), 2)) \\\n","    .withColumn(\"fuel_consumption_per_trip\", round(col(\"fuel_consumption_per_trip\"), 2)) \\\n","    .withColumn(\"fuel_cost\", round(col(\"fuel_cost\"), 2))\n","\n","# Verificar el DataFrame resultante\n","df_total_redondeado.show()\n"],"metadata":{"id":"Jlbb9RDOPYje","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713441607401,"user_tz":180,"elapsed":4016,"user":{"displayName":"Allan Alvarez","userId":"10003369821085423122"}},"outputId":"419b49ad-5ccc-4256-fdba-35c7d768b2cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------+---------+------------------------+-------------------------+------------+\n","|trip_distance|fuel_cost|fuel_efficiency_per_mile|fuel_consumption_per_trip|co2_per_mile|\n","+-------------+---------+------------------------+-------------------------+------------+\n","|          3.8|     0.46|                    8.33|                    31.67|         1.9|\n","|          2.1|     0.25|                    8.33|                     17.5|        1.05|\n","|         0.97|     0.12|                    8.33|                     8.08|       0.485|\n","|         1.09|     0.13|                    8.33|                     9.08|       0.545|\n","|          4.3|     0.52|                    8.33|                    35.83|        2.15|\n","|         10.3|     1.24|                    8.33|                    85.83|        5.15|\n","|         5.07|     0.61|                    8.33|                    42.25|       2.535|\n","|         2.02|     0.24|                    8.33|                    16.83|        1.01|\n","|         2.71|     0.33|                    8.33|                    22.58|       1.355|\n","|         0.78|     0.09|                    8.33|                      6.5|        0.39|\n","|         1.91|     0.23|                    8.33|                    15.92|       0.955|\n","|         0.82|      0.1|                    8.33|                     6.83|        0.41|\n","|         0.73|     0.09|                    8.33|                     6.08|       0.365|\n","|         2.16|     0.26|                    8.33|                     18.0|        1.08|\n","|         1.43|     0.17|                    8.33|                    11.92|       0.715|\n","|         1.58|     0.19|                    8.33|                    13.17|        0.79|\n","|          4.2|      0.5|                    8.33|                     35.0|         2.1|\n","|          2.2|     0.26|                    8.33|                    18.33|         1.1|\n","|          0.2|     0.02|                    8.33|                     1.67|         0.1|\n","|          3.9|     0.47|                    8.33|                     32.5|        1.95|\n","+-------------+---------+------------------------+-------------------------+------------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"markdown","source":["**Exporta archivo en formato parquet**"],"metadata":{"id":"91E7Dhgxu0ua"}},{"cell_type":"code","source":["'''# Ruta para guardar el archivo Parquet con el nombre \"df_ml_emis\"\n","output_path_parquet = \"/content/drive/MyDrive/Proyecto FInal Henry/DATA/df_ml_emis.parquet\"\n","\n","# Guarda el DataFrame como un solo archivo Parquet\n","merged_df_sin_nulos.coalesce(1).write.parquet(output_path_parquet, mode=\"overwrite\")'''"],"metadata":{"id":"jjPgziEmuz97","colab":{"base_uri":"https://localhost:8080/","height":73},"executionInfo":{"status":"ok","timestamp":1713441612298,"user_tz":180,"elapsed":290,"user":{"displayName":"Allan Alvarez","userId":"10003369821085423122"}},"outputId":"8c1358d0-3511-4f4c-b1f9-079ba7e31058"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'# Ruta para guardar el archivo Parquet con el nombre \"df_ml_emis\"\\noutput_path_parquet = \"/content/drive/MyDrive/Proyecto FInal Henry/DATA/df_ml_emis.parquet\"\\n\\n# Guarda el DataFrame como un solo archivo Parquet\\nmerged_df_sin_nulos.coalesce(1).write.parquet(output_path_parquet, mode=\"overwrite\")'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["**Exporta archivo en formato csv**"],"metadata":{"id":"9fg3OVlQvoDg"}},{"cell_type":"code","source":["'''\n","# Ruta para guardar el archivo CSV con el nombre \"df_ml_emis\"\n","output_path_csv = \"/content/drive/MyDrive/Proyecto FInal Henry/DATA*/df_ml_emis.csv\"\n","\n","# Guarda el DataFrame como un solo archivo CSV\n","merged_df_sin_nulos.coalesce(1).write.csv(output_path_csv, mode=\"overwrite\", header=True)'''"],"metadata":{"id":"ZA8KVY15vleY","colab":{"base_uri":"https://localhost:8080/","height":73},"executionInfo":{"status":"ok","timestamp":1713441629392,"user_tz":180,"elapsed":289,"user":{"displayName":"Allan Alvarez","userId":"10003369821085423122"}},"outputId":"f925df1e-20b6-4366-e757-dde00b3dc787"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n# Ruta para guardar el archivo CSV con el nombre \"df_ml_emis\"\\noutput_path_csv = \"/content/drive/MyDrive/Proyecto FInal Henry/DATA*/df_ml_emis.csv\"\\n\\n# Guarda el DataFrame como un solo archivo CSV\\nmerged_df_sin_nulos.coalesce(1).write.csv(output_path_csv, mode=\"overwrite\", header=True)'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["**>>> ETL MODELOS ML VIAJES Y FRANJA HORARIA**"],"metadata":{"id":"sSBqfaJQQowS"}},{"cell_type":"markdown","metadata":{"id":"NoRiaT8DERt9"},"source":["**Filtra solo las columnas necesarias para ML**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nqI34lzqWb4W"},"outputs":[],"source":["df_total_fh = df_total [['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'total_amount', 'congestion_surcharge', 'airport_fee']]"]},{"cell_type":"markdown","metadata":{"id":"c-_5SeLLbLyQ"},"source":["**Crea la columna 'date_only' solo con el valor de la fecha para hacer un merge**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XR42w0v1aiWi"},"outputs":[],"source":["# Convierte la columna 'tpep_pickup_datetime' a tipo timestamp\n","df_total_fh = df_total_fh.withColumn('tpep_pickup_datetime', F.to_timestamp(df_total_fh['tpep_pickup_datetime']))\n","\n","# Extrae la parte de la fecha y asigna a una nueva columna 'date_only'\n","df_total_fh = df_total_fh.withColumn('date_only', F.to_date(df_total_fh['tpep_pickup_datetime']))\n","\n","# Muestra el DataFrame con la nueva columna 'date_only'\n","#df_total.show()"]},{"cell_type":"markdown","metadata":{"id":"UHqR5WOBEv4g"},"source":["**DATOS DEL TIEMPO**"]},{"cell_type":"markdown","source":["**Lee y carga el archivo**"],"metadata":{"id":"uyLqWYjc5ilN"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3026,"status":"ok","timestamp":1713441643908,"user":{"displayName":"Allan Alvarez","userId":"10003369821085423122"},"user_tz":180},"id":"ZyBi9MhhYVqM","outputId":"3ce6fa74-36b6-4764-aae5-cbe21ca26d5a"},"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------------+------------------+------------------+-------------------+-----------------+\n","|               date|temperature_2m_max|temperature_2m_min|temperature_2m_mean|precipitation_sum|\n","+-------------------+------------------+------------------+-------------------+-----------------+\n","|2010-01-01 04:00:00|            5.3305|           -4.0695|         0.29091665|        1.8000001|\n","|2010-01-02 04:00:00|       -0.86950004|           -9.3695|         -3.5465834|              0.7|\n","|2010-01-03 04:00:00|        -4.8694997|          -10.1195|         -7.6820006|              0.0|\n","|2010-01-04 04:00:00|           -0.7195|           -7.3195|          -4.873667|              0.0|\n","|2010-01-05 04:00:00|      -0.119500004|        -7.3694997|         -4.6486664|              0.0|\n","|2010-01-06 04:00:00|            1.1805|        -5.3694997|         -2.8653333|              0.0|\n","|2010-01-07 04:00:00|            3.6805|           -3.8195|         -1.2924166|              0.0|\n","|2010-01-08 04:00:00|            2.0805|           -5.9195|         -1.5611666|       0.70000005|\n","|2010-01-09 04:00:00|           -1.3195|        -7.9694996|          -5.654917|              0.0|\n","|2010-01-10 04:00:00|           -1.5695|          -10.4695|         -6.7007504|              0.0|\n","|2010-01-11 04:00:00|            0.7805|        -7.7194996|         -4.1486664|              0.0|\n","|2010-01-12 04:00:00|            2.1305|        -4.9694996|          -2.254917|              0.0|\n","|2010-01-13 04:00:00|            2.3305|        -5.9694996|         -2.9236662|              0.0|\n","|2010-01-14 04:00:00|            4.4805|        -4.3694997|         -0.8174166|              0.0|\n","|2010-01-15 04:00:00|          8.580501|           -2.4695|          1.7492499|              0.0|\n","|2010-01-16 04:00:00|            8.6305|           -2.0695|          1.7430001|              0.0|\n","|2010-01-17 04:00:00|         4.5305004|           -2.3195|            1.02425|        7.1000004|\n","|2010-01-18 04:00:00|            9.4805|         1.2804999|           4.278417|        2.3999999|\n","|2010-01-19 04:00:00|          8.580501|           -1.0195|          3.2325833|              0.0|\n","|2010-01-20 04:00:00|            5.3305|           -2.3195|         0.67216665|              0.0|\n","+-------------------+------------------+------------------+-------------------+-----------------+\n","only showing top 20 rows\n","\n"]}],"source":["# Especifica la ruta del archivo CSV en Google Drive\n","ruta_archivo_csv = '/content/drive/MyDrive/Proyecto FInal Henry/DATA*/daily_weather_data.csv'\n","\n","# Leer el archivo CSV en un DataFrame de PySpark\n","  daily_weather_data = spark.read.csv(ruta_archivo_csv, header=True, inferSchema=True)\n","\n","# Mostrar el DataFrame\n","daily_weather_data.show()"]},{"cell_type":"markdown","metadata":{"id":"EsaM4UTsJLEo"},"source":["**Filtra el dataframe con la columnasnecesarias para el ML**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":270,"status":"ok","timestamp":1713441649848,"user":{"displayName":"Allan Alvarez","userId":"10003369821085423122"},"user_tz":180},"id":"bQOHifS-ZI0i","outputId":"bf58dcae-7102-44e2-f495-f22752412e19"},"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------------+-------------------+-----------------+\n","|               date|temperature_2m_mean|precipitation_sum|\n","+-------------------+-------------------+-----------------+\n","|2010-01-01 04:00:00|         0.29091665|        1.8000001|\n","|2010-01-02 04:00:00|         -3.5465834|              0.7|\n","|2010-01-03 04:00:00|         -7.6820006|              0.0|\n","|2010-01-04 04:00:00|          -4.873667|              0.0|\n","|2010-01-05 04:00:00|         -4.6486664|              0.0|\n","|2010-01-06 04:00:00|         -2.8653333|              0.0|\n","|2010-01-07 04:00:00|         -1.2924166|              0.0|\n","|2010-01-08 04:00:00|         -1.5611666|       0.70000005|\n","|2010-01-09 04:00:00|          -5.654917|              0.0|\n","|2010-01-10 04:00:00|         -6.7007504|              0.0|\n","|2010-01-11 04:00:00|         -4.1486664|              0.0|\n","|2010-01-12 04:00:00|          -2.254917|              0.0|\n","|2010-01-13 04:00:00|         -2.9236662|              0.0|\n","|2010-01-14 04:00:00|         -0.8174166|              0.0|\n","|2010-01-15 04:00:00|          1.7492499|              0.0|\n","|2010-01-16 04:00:00|          1.7430001|              0.0|\n","|2010-01-17 04:00:00|            1.02425|        7.1000004|\n","|2010-01-18 04:00:00|           4.278417|        2.3999999|\n","|2010-01-19 04:00:00|          3.2325833|              0.0|\n","|2010-01-20 04:00:00|         0.67216665|              0.0|\n","+-------------------+-------------------+-----------------+\n","only showing top 20 rows\n","\n"]}],"source":["daily_weather_data = daily_weather_data [['date', 'temperature_2m_mean', 'precipitation_sum']]\n","daily_weather_data.show()"]},{"cell_type":"markdown","metadata":{"id":"1FCYdeqfZ9Lf"},"source":["**Crea la columna 'date_only' solo con el valor de la fecha para hacer un merge**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A8IjDRJfZIx5"},"outputs":[],"source":["# Convierte la columna 'date' a tipo timestamp\n","daily_weather_data = daily_weather_data.withColumn('date', F.to_timestamp(daily_weather_data['date']))\n","\n","# Extrae la parte de la fecha y asigna a una nueva columna 'date_only'\n","daily_weather_data = daily_weather_data.withColumn('date_only', F.to_date(daily_weather_data['date']))\n","\n","# Muestra el DataFrame con la nueva columna 'date_only'\n","#daily_weather_data.show()"]},{"cell_type":"markdown","metadata":{"id":"j3CgnI-rcChH"},"source":["**Realiza la union de ambos dataframes**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sx-hDfWPZIvR"},"outputs":[],"source":["# Realizar la unión de DataFrames en PySpark\n","merged_df = df_total_fh.join(daily_weather_data, on='date_only', how='left')\n","\n","# Mostrar el DataFrame resultante\n","#merged_df.show()\n"]},{"cell_type":"markdown","metadata":{"id":"qPgcSyztcRln"},"source":["**Imputacion de nulos**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"10s-zobzZIsx"},"outputs":[],"source":["# Reemplazar los valores nulos en la columna 'passenger_count' con 1\n","merged_df = merged_df.withColumn('passenger_count', when(merged_df['passenger_count'].isNull(), 1).otherwise(merged_df['passenger_count']))\n","\n","# Reemplazar los valores nulos en la columna 'congestion_surcharge' con 0\n","merged_df = merged_df.withColumn('congestion_surcharge', when(merged_df['congestion_surcharge'].isNull(), 0).otherwise(merged_df['congestion_surcharge']))\n","\n","# Reemplazar los valores nulos en la columna 'airport_fee' con 0\n","merged_df = merged_df.withColumn('airport_fee', when(merged_df['airport_fee'].isNull(), 0).otherwise(merged_df['airport_fee']))\n","\n","# Mostrar el DataFrame resultante\n","#merged_df.show()\n"]},{"cell_type":"markdown","metadata":{"id":"zHSZhtIDdp45"},"source":["**Elimina filas con valores nulos**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zkbDAhtjWbym"},"outputs":[],"source":["# Eliminar filas con valores nulos\n","merged_df_sin_nulos = merged_df.na.drop()"]},{"cell_type":"markdown","metadata":{"id":"aPEbp5oXh_wl"},"source":["**Convierte las columnas de precipitaciones, congestion y aeropuerto en 0 si no ocurrió el evento y 1 si ocurrió**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eDfDykQehXSz"},"outputs":[],"source":["# Reemplazar los valores distintos de cero por 1 en la columna 'temperature_2m_mean'\n","merged_df_sin_nulos = merged_df_sin_nulos.withColumn('precipitation_sum', when(merged_df_sin_nulos['precipitation_sum'] != 0, 1).otherwise(0))\n","\n","# Reemplazar los valores distintos de cero por 1 en la columna 'congestion_surcharge'\n","merged_df_sin_nulos = merged_df_sin_nulos.withColumn('congestion_surcharge', when(merged_df_sin_nulos['congestion_surcharge'] != 0, 1).otherwise(0))\n","\n","# Reemplazar los valores distintos de cero por 1 en la columna 'airport_fee'\n","merged_df_sin_nulos = merged_df_sin_nulos.withColumn('airport_fee', when(merged_df_sin_nulos['airport_fee'] != 0, 1).otherwise(0))\n","\n","# Mostrar el DataFrame resultante\n","#merged_df_sin_nulos.show()"]},{"cell_type":"markdown","metadata":{"id":"5-oQQ1lQiE9A"},"source":["**MODIFICANDO GRANULARIDAD DE LOS DATOS**"]},{"cell_type":"markdown","metadata":{"id":"gehLemVUjOPn"},"source":["**Crea la columna franja horaria a partir de la hora de iniciado el viaje 'tpep_pickup_datetime'**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AfuFHHkRhXQC"},"outputs":[],"source":["# Convertir la columna 'tpep_pickup_datetime' a tipo timestamp\n","merged_df_sin_nulos = merged_df_sin_nulos.withColumn('tpep_pickup_datetime', F.to_timestamp(merged_df_sin_nulos['tpep_pickup_datetime']))\n","\n","# Extraer la hora de la columna 'tpep_pickup_datetime' y asignarla a la nueva columna 'franja_horaria'\n","merged_df_sin_nulos = merged_df_sin_nulos.withColumn('franja_horaria', hour(merged_df_sin_nulos['tpep_pickup_datetime']))\n","\n","# Mostrar el DataFrame resultante\n","#merged_df_sin_nulos.show()\n"]},{"cell_type":"markdown","metadata":{"id":"kKoKjEG-jLEH"},"source":["**Calcula la duración del viaje en minutos restando las columnas de inicio y fin del viaje**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DCWWQCdQij8T"},"outputs":[],"source":["# Convertir las columnas 'tpep_pickup_datetime' y 'tpep_dropoff_datetime' a tipo datetime si no lo están\n","merged_df_sin_nulos = merged_df_sin_nulos.withColumn('tpep_pickup_datetime', to_timestamp(merged_df_sin_nulos['tpep_pickup_datetime']))\n","merged_df_sin_nulos = merged_df_sin_nulos.withColumn('tpep_dropoff_datetime', to_timestamp(merged_df_sin_nulos['tpep_dropoff_datetime']))\n","\n","# Calcular la duración del viaje en minutos y redondear el resultado a 2 decimales\n","merged_df_sin_nulos = merged_df_sin_nulos.withColumn('duracion_viaje_minutos',\n","                                                     round(((F.col('tpep_dropoff_datetime').cast('long') - F.col('tpep_pickup_datetime').cast('long')) / 60), 2))\n","\n","# Mostrar el DataFrame con la nueva columna\n","#merged_df_sin_nulos.show()\n"]},{"cell_type":"markdown","metadata":{"id":"J5kJr4R1lsrh"},"source":["**Agrupa las columnas por fechas y franjas horarias**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HpQt3fOFij3D"},"outputs":[],"source":["# Define la ventana de partición\n","window_spec = Window.partitionBy('date_only', 'franja_horaria')\n","\n","# Agrupar por fecha y franja horaria y sumar los viajes en cada grupo\n","merged_df_sin_nulos = merged_df_sin_nulos.withColumn('suma_viajes', F.count('passenger_count').over(window_spec))\n","\n","# Agrupar por fecha y franja horaria y sumar los pasajeros en cada grupo\n","merged_df_sin_nulos = merged_df_sin_nulos.withColumn('suma_pasajeros', F.sum('passenger_count').over(window_spec))\n","\n","# Aquí agrupamos por 'date_only' y 'franja_horaria' y sumamos 'trip_distance'\n","merged_df_sin_nulos = merged_df_sin_nulos.withColumn('suma_distancias', F.sum('trip_distance').over(window_spec))\n","\n","# Aquí agrupamos por 'date_only' y 'franja_horaria' y sumamos 'total_amount'\n","merged_df_sin_nulos = merged_df_sin_nulos.withColumn('suma_tarifas', F.sum('total_amount').over(window_spec))\n","\n","# Aquí agrupamos por 'date_only' y 'franja_horaria' y promediamos 'congestion_surcharge'\n","merged_df_sin_nulos = merged_df_sin_nulos.withColumn('promedio_congestion', F.avg('congestion_surcharge').over(window_spec))\n","\n","# Aquí agrupamos por 'date_only' y 'franja_horaria' y promediamos 'airport_fee'\n","merged_df_sin_nulos = merged_df_sin_nulos.withColumn('promedio_aeropuerto', F.avg('airport_fee').over(window_spec))\n","\n","# Aquí agrupamos por 'date_only' y 'franja_horaria' y promediamos 'temperature_2m_mean'\n","merged_df_sin_nulos = merged_df_sin_nulos.withColumn('promedio_temperatura', F.avg('temperature_2m_mean').over(window_spec))\n","\n","# Aquí agrupamos por 'date_only' y 'franja_horaria' y promediamos 'precipitation_sum'\n","merged_df_sin_nulos = merged_df_sin_nulos.withColumn('promedio_presipitaciones', F.avg('precipitation_sum').over(window_spec))\n","\n","# Aquí agrupamos por 'date_only' y 'franja_horaria' y sumamos 'duracion_viaje_minutos'\n","merged_df_sin_nulos = merged_df_sin_nulos.withColumn('suma_duracion_viajes_minutos', F.sum('duracion_viaje_minutos').over(window_spec))\n","\n","\n","# Redondear todas las salidas a 2 decimales\n","merged_df_sin_nulos = merged_df_sin_nulos.withColumn('suma_viajes', F.round('suma_viajes', 2))\n","merged_df_sin_nulos = merged_df_sin_nulos.withColumn('suma_pasajeros', F.round('suma_pasajeros', 2))\n","merged_df_sin_nulos = merged_df_sin_nulos.withColumn('suma_distancias', F.round('suma_distancias', 2))\n","merged_df_sin_nulos = merged_df_sin_nulos.withColumn('suma_tarifas', F.round('suma_tarifas', 2))\n","merged_df_sin_nulos = merged_df_sin_nulos.withColumn('promedio_congestion', F.round('promedio_congestion', 2))\n","merged_df_sin_nulos = merged_df_sin_nulos.withColumn('promedio_aeropuerto', F.round('promedio_aeropuerto', 2))\n","merged_df_sin_nulos = merged_df_sin_nulos.withColumn('promedio_temperatura', F.round('promedio_temperatura', 2))\n","merged_df_sin_nulos = merged_df_sin_nulos.withColumn('promedio_presipitaciones', F.round('promedio_presipitaciones', 2))\n","merged_df_sin_nulos = merged_df_sin_nulos.withColumn('suma_duracion_viajes_minutos', F.round('suma_duracion_viajes_minutos', 2))\n","\n","# Mostrar el DataFrame resultante\n","#merged_df_sin_nulos.show()\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ulkpC9qQlw-5"},"source":["**Elimina columnas innecesarias**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zkhJQUQJij0T"},"outputs":[],"source":["# Lista de columnas a eliminar\n","columnas_a_eliminar = ['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'duracion_viaje_minutos','passenger_count', 'trip_distance', 'total_amount', 'congestion_surcharge', 'airport_fee', 'pickup_date', 'date', 'temperature_2m_mean', 'precipitation_sum']\n","\n","# Eliminar las columnas\n","merged_df_sin_nulos = merged_df_sin_nulos.drop(*columnas_a_eliminar)\n","\n","# Mostrar el DataFrame resultante\n","#merged_df_sin_nulos.show()"]},{"cell_type":"markdown","metadata":{"id":"hdnkYvOnsdbP"},"source":["**Elimina filas duplicadas**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tE3TyRu2hXLL"},"outputs":[],"source":["# Eliminar filas completamente duplicadas\n","merged_df_sin_nulos = merged_df_sin_nulos.dropDuplicates()\n"]},{"cell_type":"code","source":["# Mostrar el DataFrame resultante\n","merged_df_sin_nulos.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eD4JDjdWtaIZ","executionInfo":{"status":"ok","timestamp":1713441921568,"user_tz":180,"elapsed":234124,"user":{"displayName":"Allan Alvarez","userId":"10003369821085423122"}},"outputId":"93af180b-0b8a-4dd5-c579-0609b5c86d9c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+--------------+-----------+--------------+---------------+------------+-------------------+-------------------+--------------------+------------------------+----------------------------+\n","| date_only|franja_horaria|suma_viajes|suma_pasajeros|suma_distancias|suma_tarifas|promedio_congestion|promedio_aeropuerto|promedio_temperatura|promedio_presipitaciones|suma_duracion_viajes_minutos|\n","+----------+--------------+-----------+--------------+---------------+------------+-------------------+-------------------+--------------------+------------------------+----------------------------+\n","|2022-01-01|            14|       3324|        5220.0|       37575.27|    73869.51|               0.87|                0.1|                9.66|                     1.0|                     56106.3|\n","|2022-01-01|            21|       2703|        4176.0|       10739.83|    57309.62|               0.87|               0.13|                9.66|                     1.0|                    44048.79|\n","|2022-01-02|             1|       1016|        1594.0|         5050.8|    24711.37|               0.83|               0.16|                9.64|                     1.0|                    17127.36|\n","|2022-01-03|            12|       4498|        6368.0|       13423.19|    80529.33|                0.9|               0.06|               -1.11|                     1.0|                    63098.02|\n","|2022-01-04|            18|       5346|        7413.0|       17106.12|   104126.33|               0.89|               0.08|               -3.05|                     0.0|                    66782.57|\n","|2022-01-06|             4|        210|         280.0|         889.55|     4495.52|               0.81|               0.01|                1.95|                     0.0|                     2626.87|\n","|2022-01-08|             0|       2984|        4370.0|       10537.01|    58314.37|               0.88|               0.08|               -5.77|                     0.0|                    40282.56|\n","|2022-01-08|            13|       5170|        7621.0|       15576.88|    92974.91|               0.91|               0.06|               -5.77|                     0.0|                    65719.11|\n","|2022-01-11|            22|       2464|        3366.0|        9135.37|    49725.73|               0.88|                0.1|               -6.91|                     0.0|                     32286.9|\n","|2022-01-13|            14|       5844|        8025.0|       17312.74|   109395.03|               0.92|               0.06|                1.04|                     0.0|                    94679.48|\n","|2022-01-13|            20|       4141|        5692.0|        13535.0|    79354.06|               0.91|               0.07|                1.04|                     0.0|                     54512.9|\n","|2022-01-15|            18|       5614|        8151.0|      122430.07|    98406.43|               0.91|               0.05|               -7.92|                     0.0|                    86406.59|\n","|2022-01-17|            10|       3005|        4116.0|        9503.51|    55295.15|               0.89|               0.07|                3.61|                     1.0|                    39583.43|\n","|2022-01-18|             8|       4681|        5994.0|       18049.17|    84112.57|               0.88|               0.04|               -0.85|                     0.0|                    75219.74|\n","|2022-01-20|             9|       4709|        5965.0|       11216.82|    80428.97|               0.91|               0.03|                0.89|                     1.0|                    66505.99|\n","|2022-01-21|             4|        338|         473.0|        1345.46|     6991.21|               0.82|               0.02|               -7.99|                     0.0|                     4039.04|\n","|2022-01-22|             3|       1711|        2504.0|        5277.51|    31671.39|               0.92|               0.01|               -6.76|                     0.0|                    21285.38|\n","|2022-01-22|            20|       4987|        7320.0|       14629.23|    93038.14|               0.91|               0.05|               -6.76|                     0.0|                    70828.71|\n","|2022-01-23|             4|       1015|        1456.0|         3472.2|    19811.52|               0.91|               0.01|               -2.09|                     1.0|                     12336.3|\n","|2022-01-25|            19|       5639|        7461.0|       16261.08|   103221.95|               0.93|               0.05|                1.62|                     0.0|                    72143.89|\n","+----------+--------------+-----------+--------------+---------------+------------+-------------------+-------------------+--------------------+------------------------+----------------------------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"markdown","source":["**Exporta archivo en formato parquet**"],"metadata":{"id":"lQaLWLQb4Kw7"}},{"cell_type":"code","source":["'''# Ruta para guardar el archivo Parquet con el nombre \"df_ml_fh\"\n","output_path_parquet = \"/content/drive/MyDrive/Proyecto FInal Henry/DATA/df_ml_fh.parquet\"\n","\n","# Guarda el DataFrame como un solo archivo Parquet\n","merged_df_sin_nulos.coalesce(1).write.parquet(output_path_parquet, mode=\"overwrite\")'''\n","\n","\n"],"metadata":{"id":"vipSBnVJ4KP7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Exporta archivo en formato csv**"],"metadata":{"id":"ftVffNsiO4mb"}},{"cell_type":"code","source":["'''\n","# Ruta para guardar el archivo CSV con el nombre \"df_ml_fh\"\n","output_path_csv = \"/content/drive/MyDrive/Proyecto FInal Henry/DATA*/df_ml_fh.csv\"\n","\n","# Guarda el DataFrame como un solo archivo CSV\n","merged_df_sin_nulos.coalesce(1).write.csv(output_path_csv, mode=\"overwrite\", header=True)\n","\n","'''\n"],"metadata":{"id":"uIg3I9vUi1-u"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1mASFidWTVUu9YFeW2hdM4hyrwT_CY_Ei","timestamp":1713275745667},{"file_id":"1YPRRfGyNpUe0uIgtaHTqcCQq9b0xucWm","timestamp":1712606873378}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}